import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

print("=" * 50)
print("ШАГ 1: Загрузка и первичный осмотр данных")
print("=" * 50)

try:
    df = pd.read_csv('ncr_ride_bookings.csv')
    print("Файл 'ncr_ride_bookings.csv' загружен успешно!")
except FileNotFoundError:
    print("ОШИБКА: Файл не найден!")
    exit()

# Мы показываем 5 строк данных чтобы понять структуру
print("\n1. Первые 5 строк данных:")
print(df.head())
print("\n" + "-" * 30)

# Показываем количество записей, пропуски и количество столбцов
print("2. Общая информация о данных:")
df.info()
print("\n" + "-" * 30)

# Статистика числовых столбцов: среднее, минимальные и максимальные
print("3. Статистическое описание числовых столбцов:")
print(df.describe())
print("\n" + "-" * 30)

# Сколько строк и столбцов
print("4. Количество строк и столбцов:")
print(f"Строк: {df.shape[0]}, Столбцов: {df.shape[1]}")
print("\n" + "-" * 30)

# Все названия столбцов
print("ВСЕ СТОЛБЦЫ В ДАННЫХ:")
for i, col in enumerate(df.columns, 1):
    print(f"{i}. {col}")

print("\n" + "-" * 30)

print("=" * 50)
print("ШАГ 2: СТАТИСТИЧЕСКИЙ ОБЗОР ДАННЫХ")
print("=" * 50)

print("1. Количество пропущенных значений в каждом столбце:")
missing_values = df.isnull().sum()  # Считаем количество пропусков (NaN)
missing_percentage = (df.isnull().sum() / len(df)) * 100  # Процент пропусков
missing_info = pd.DataFrame({
    'Пропущенные значения': missing_values,
    'Процент пропусков': missing_percentage.round(2)
})  # Создание красивую таблицу
print(missing_info)
print("\n" + "-" * 30)

print("2. Общая статистика по пропущенным значениям:")
print(f"Всего пропущенных значений в датасете: {df.isnull().sum().sum()}")
print(f"Столбцов с пропусками: {(missing_values > 0).sum()} из {len(df.columns)}")
print("\n" + "-" * 30)

print("3. Типы данных в каждом столбце:")
dtypes_info = pd.DataFrame({
    'Тип данных': df.dtypes,
    'Уникальных значений': df.nunique()
})
print(dtypes_info)
print("\n" + "-" * 30)

# Список всех названий столбцов
all_columns = df.columns.tolist()
status_cols = [col for col in all_columns if 'status' in col.lower()]  # Статусы
# Типы транспорта
vehicle_cols = [col for col in all_columns if 'vehicle' in col.lower() or 'auto' in col.lower()]

status_col = status_cols[0] if status_cols else 'Booking Status'
vehicle_col = vehicle_cols[0] if vehicle_cols else 'Vehicle Type'

print("4. Анализ категориальных столбцов:")

if status_col in df.columns:
    print(f"\nУникальные значения в '{status_col}':")  # Все значения и их частоту
    print(df[status_col].value_counts())
    print(f"Всего уникальных статусов: {df[status_col].nunique()}")  # Уникальные значения считаем
    print(f"Пропущенных значений: {df[status_col].isnull().sum()}")  # Считаем пропуски в этом столбце
else:
    print(f"Столбец '{status_col}' не найден в данных")

if vehicle_col in df.columns:
    print(f"\nУникальные значения в '{vehicle_col}':")
    print(df[vehicle_col].value_counts())
    print(f"Всего уникальных типов транспорта: {df[vehicle_col].nunique()}")
    print(f"Пропущенных значений: {df[vehicle_col].isnull().sum()}")
else:
    print(f"Столбец '{vehicle_col}' не найден в данных")

print("\n" + "-" * 30)

print("5. Базовая статистика для числовых столбцов:")
numeric_columns = df.select_dtypes(include=[np.number]).columns  # Выбираем только числовые столбцы
if len(numeric_columns) > 0:
    # Показываем статистику для числовых столбцов
    numeric_stats = df[numeric_columns].describe()
    print(numeric_stats)
else:
    print("Числовые столбцы не найдены")

print("\n" + "-" * 30)

print("=" * 50)
print("ШАГ 3: Выборка и фильтрация данных")
print("=" * 50)

# Ищем столбец с ID бронирования (содержит 'booking' и 'id')
booking_id_cols = [col for col in all_columns if 'booking' in col.lower() and 'id' in col.lower()]
# Ищем столбцы с датой/временем (содержат 'date', 'time' или 'datetime')
datetime_cols = [col for col in all_columns if any(x in col.lower() for x in ['date', 'time', 'datetime'])]
# Ищем столбцы с оплатой (содержат 'payment')
payment_cols = [col for col in all_columns if 'payment' in col.lower()]
# Ищем столбцы со стоимостью (содержат 'value', 'price' или 'cost')
value_cols = [col for col in all_columns if 'value' in col.lower() or 'price' in col.lower() or 'cost' in col.lower()]

print(f"Возможные столбцы для Booking ID: {booking_id_cols}")
print(f"Возможные столбцы для даты/времени: {datetime_cols}")
print(f"Возможные столбцы для статуса: {status_cols}")
print(f"Возможные столбцы для типа транспорта: {vehicle_cols}")
print(f"Возможные столбцы для оплаты: {payment_cols}")
print(f"Возможные столбцы для стоимости: {value_cols}")

# ВЫБИРАЕМ СТОЛБЦЫ ДЛЯ РАБОТЫ:
booking_id_col = booking_id_cols[0] if booking_id_cols else 'Booking ID'
datetime_col = datetime_cols[0] if datetime_cols else 'booking_datetime'
payment_col = payment_cols[0] if payment_cols else 'Payment Method'
value_col = value_cols[0] if value_cols else 'Booking Value'

# ПОКАЗЫВАЕМ КАКИЕ СТОЛБЦЫ БУДЕМ ИСПОЛЬЗОВАТЬ:
print(f"\nИспользуем столбцы:")
print(f"Booking ID: {booking_id_col}")
print(f"Дата/время: {datetime_col}")
print(f"Статус: {status_col}")
print(f"Тип транспорта: {vehicle_col}")
print(f"Оплата: {payment_col}")
print(f"Стоимость: {value_col}")

print("\n" + "-" * 30)

print("1. Выбранные столбцы (первые 5 строк):")
try:
    # Выбираем только нужные столбцы для показа
    selected_columns = df[[booking_id_col, datetime_col, status_col, vehicle_col, payment_col]]
    print(selected_columns.head())
except KeyError as e:
    # Если какой-то столбец не найден - сообщаем об ошибке
    print(f"Ошибка: столбец {e} не найден. Проверьте названия столбцов.")

print("\n" + "-" * 30)

# Фильтруем данные: только строки где статус = 'Cancelled by Driver'
print("2. Бронирования со статусом 'Cancelled by Driver':")
try:
    cancelled_by_driver = df[df[status_col] == 'Cancelled by Driver']
    print(cancelled_by_driver)  # показываем результат
    print(f"Найдено: {len(cancelled_by_driver)} записей")  # считаем
except KeyError:
    print("Столбец статуса не найден")

print("\n" + "-" * 30)

# Двойное условие: тип транспорта = Auto И стоимость > 500
print("3. Бронирования Auto с Booking Value > 500:")
try:
    auto_high_value = df[(df[vehicle_col] == 'Auto') & (df[value_col] > 500)]
    print(auto_high_value)
    print(f"Найдено: {len(auto_high_value)} записей")
except KeyError:
    print("Не удалось выполнить фильтрацию. Проверьте названия столбцов.")

print("\n" + "-" * 30)

print("4. Бронирования за март 2024 года:")
try:
    # Преобразуем текст в формат даты для работы с датами
    df[datetime_col] = pd.to_datetime(df[datetime_col])
    march_2024 = df[(df[datetime_col] >= '2024-03-01') & (df[datetime_col] <= '2024-03-31')]
    print(march_2024)
    print(f"Найдено: {len(march_2024)} записей")
except KeyError:
    print("Столбец с датой не найден")
except Exception as e:
    print(f"Ошибка при работе с датами: {e}")

print("\n" + "-" * 30)

print("=" * 50)
print("ШАГ 4: ПОДГОТОВКА ДАННЫХ ДЛЯ МАШИННОГО ОБУЧЕНИЯ")
print("=" * 50)

# Определяем целевой признак - прогнозируем отмену поездок
print("1. Анализ целевой переменной (статус бронирования):")
if status_col in df.columns:
    print("Распределение статусов:")
    status_counts = df[status_col].value_counts()
    print(status_counts)

    # Создаем бинарную целевую переменную: 1 - отменено, 0 - не отменено
    # Адаптируем под ваши данные - смотрим какие статусы есть
    cancellation_keywords = ['cancel', 'cancelled', 'отмен', 'canceled']

    # Проверяем какие статусы содержат ключевые слова об отмене
    df['is_cancelled'] = 0
    for keyword in cancellation_keywords:
        mask = df[status_col].astype(str).str.lower().str.contains(keyword, na=False)
        df.loc[mask, 'is_cancelled'] = 1

    print(f"\nЦелевая переменная создана:")
    print(f"Отмененные поездки: {df['is_cancelled'].sum()} ({df['is_cancelled'].mean() * 100:.1f}%)")
    print(f"Не отмененные поездки: {len(df) - df['is_cancelled'].sum()} ({(1 - df['is_cancelled'].mean()) * 100:.1f}%)")
else:
    print("Столбец статуса не найден!")
    exit()

print("\n" + "-" * 30)

print("2. Подготовка признаков для модели:")
# Выбираем потенциально полезные признаки
feature_columns = []

# Числовые признаки
numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()
if value_col in df.columns:
    feature_columns.append(value_col)
    print(f"Добавлен числовой признак: {value_col}")

# Категориальные признаки
categorical_features = []
if vehicle_col in df.columns:
    categorical_features.append(vehicle_col)
    print(f"Добавлен категориальный признак: {vehicle_col}")
if payment_col in df.columns:
    categorical_features.append(payment_col)
    print(f"Добавлен категориальный признак: {payment_col}")

# Временные признаки (если есть дата/время)
if datetime_col in df.columns:
    try:
        df[datetime_col] = pd.to_datetime(df[datetime_col])
        df['hour'] = df[datetime_col].dt.hour
        df['day_of_week'] = df[datetime_col].dt.dayofweek
        df['is_weekend'] = (df[datetime_col].dt.dayofweek >= 5).astype(int)

        feature_columns.extend(['hour', 'day_of_week', 'is_weekend'])
        print("Добавлены временные признаки: hour, day_of_week, is_weekend")
    except Exception as e:
        print(f"Не удалось извлечь временные признаки: {e}")

print(f"\nВсего признаков для модели: {len(feature_columns + categorical_features)}")

print("\n" + "-" * 30)

print("3. Предобработка данных:")
# Копируем данные для модели
model_df = df[feature_columns + categorical_features + ['is_cancelled']].copy()

# Заполняем пропуски
print("Заполнение пропущенных значений...")
for col in model_df.columns:
    if model_df[col].isnull().sum() > 0:
        if model_df[col].dtype in ['float64', 'int64']:
            model_df[col].fillna(model_df[col].median(), inplace=True)
            print(f"Заполнены пропуски в {col} медианой")
        else:
            model_df[col].fillna(model_df[col].mode()[0], inplace=True)
            print(f"Заполнены пропуски в {col} модой")

# Кодируем категориальные переменные
print("Кодирование категориальных переменных...")
label_encoders = {}
for col in categorical_features:
    if col in model_df.columns:
        le = LabelEncoder()
        model_df[col] = le.fit_transform(model_df[col].astype(str))
        label_encoders[col] = le
        print(f"Закодирован признак: {col}")

print("\nДанные после предобработки:")
print(f"Размерность: {model_df.shape}")
print(f"Признаки: {list(model_df.columns)}")

print("\n" + "-" * 30)

print("4. Разделение данных на обучающую и тестовую выборки:")
X = model_df.drop('is_cancelled', axis=1)
y = model_df['is_cancelled']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Обучающая выборка: {X_train.shape[0]} записей")
print(f"Тестовая выборка: {X_test.shape[0]} записей")
print(f"Количество признаков: {X_train.shape[1]}")

print("\n" + "-" * 30)

print("=" * 50)
print("ШАГ 5: ОБУЧЕНИЕ МОДЕЛИ МАШИННОГО ОБУЧЕНИЯ")
print("=" * 50)

print("Обучение модели Random Forest...")
model = RandomForestClassifier(
    n_estimators=100,
    random_state=42,
    max_depth=10,
    class_weight='balanced'
)

model.fit(X_train, y_train)

print("Модель обучена успешно!")

print("\n" + "-" * 30)

print("6. Оценка качества модели:")
y_pred = model.predict(X_test)

print("Точность модели:", accuracy_score(y_test, y_pred))
print("\nОтчет по классификации:")
print(classification_report(y_test, y_pred))

print("\nМатрица ошибок:")
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Не отменена', 'Отменена'],
            yticklabels=['Не отменена', 'Отменена'])
plt.title('Матрица ошибок')
plt.ylabel('Фактические значения')
plt.xlabel('Предсказанные значения')
plt.show()

print("\n" + "-" * 30)

print("7. Важность признаков:")
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

print("Топ-10 самых важных признаков:")
print(feature_importance.head(10))

# Визуализация важности признаков
plt.figure(figsize=(10, 6))
sns.barplot(data=feature_importance.head(10), x='importance', y='feature')
plt.title('Топ-10 самых важных признаков для прогноза отмен')
plt.xlabel('Важность признака')
plt.tight_layout()
plt.show()

print("\n" + "-" * 30)

print("=" * 50)
print("ШАГ 6: ПРИМЕР ПРОГНОЗИРОВАНИЯ")
print("=" * 50)

print("Пример прогноза для новых данных:")
# Берем несколько примеров из тестовой выборки
sample_data = X_test.head(5)
predictions = model.predict(sample_data)
prediction_proba = model.predict_proba(sample_data)

print("\nПрогнозы для 5 примеров:")
for i, (idx, row) in enumerate(sample_data.iterrows()):
    actual = y_test.loc[idx]
    predicted = predictions[i]
    probability = prediction_proba[i][1]  # Вероятность отмены

    status = "ОТМЕНА" if predicted == 1 else "НЕТ ОТМЕНЫ"
    actual_status = "ОТМЕНА" if actual == 1 else "НЕТ ОТМЕНЫ"
    correct = "✓" if predicted == actual else "✗"

    print(f"Пример {i + 1}: Прогноз - {status} (вероятность: {probability:.2f}), Факт - {actual_status} {correct}")

print("\n" + "-" * 30)

print("8. Анализ бизнес-инсайтов:")
cancellation_rate = df['is_cancelled'].mean()
print(f"Общий уровень отмен: {cancellation_rate * 100:.1f}%")

if 'hour' in model_df.columns:
    hourly_cancellation = df.groupby('hour')['is_cancelled'].mean()
    peak_hour = hourly_cancellation.idxmax()
    print(f"Час с наибольшим количеством отмен: {peak_hour}:00 ({hourly_cancellation.max() * 100:.1f}%)")

if vehicle_col in df.columns and vehicle_col in label_encoders:
    # Декодируем обратно для читаемости
    vehicle_cancellation = df.groupby(vehicle_col)['is_cancelled'].mean()
    worst_vehicle = vehicle_cancellation.idxmax()
    print(f"Тип транспорта с наибольшим количеством отмен: {worst_vehicle} ({vehicle_cancellation.max() * 100:.1f}%)")

if payment_col in df.columns and payment_col in label_encoders:
    payment_cancellation = df.groupby(payment_col)['is_cancelled'].mean()
    worst_payment = payment_cancellation.idxmax()
    print(f"Метод оплаты с наибольшим количеством отмен: {worst_payment} ({payment_cancellation.max() * 100:.1f}%)")

print("\n" + "-" * 30)

print("РЕКОМЕНДАЦИИ ДЛЯ БИЗНЕСА:")
print("1. Сфокусируйтесь на часах пик для уменьшения отмен")
print("2. Проанализируйте проблемные типы транспорта")
print("3. Улучшите процессы для проблемных методов оплаты")
print("4. Используйте модель для прогнозирования риска отмены в реальном времени")

print("=" * 50)
print("МОДЕЛЬ МАШИННОГО ОБУЧЕНИЯ ОБУЧЕНА!")
print("=" * 50)
print("ЧТО МЫ СДЕЛАЛИ:")
print("✓ Проанализировали данные о бронированиях")
print("✓ Подготовили данные для машинного обучения")
print("✓ Обучили модель для прогнозирования отмен поездок")
print("✓ Оценили качество модели и важность признаков")
print("✓ Получили бизнес-инсайты для уменьшения отмен")
print("=" * 50)
