–ü—Ä–∞–∫—Ç–∏–∫–∞ 4. –ú–ê–®–ò–ù–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
from scipy import stats
from sklearn.cluster import KMeans

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
pd.set_option('display.max_columns', None)
pd.set_option('display.width', 1000)
pd.set_option('display.max_rows', 50)
warnings.filterwarnings('ignore')

print("=" * 100)
print("–ü–û–õ–ù–ê–Ø –ú–û–î–ï–õ–¨ –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø –°–¢–û–ò–ú–û–°–¢–ò –ü–û–ï–ó–î–û–ö")
print("=" * 100)

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
try:
    df = pd.read_csv('ncr_ride_bookings.csv')
    print("‚úÖ –§–∞–π–ª 'ncr_ride_bookings.csv' –∑–∞–≥—Ä—É–∂–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
    print(f"üìä –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {df.shape}")
except FileNotFoundError:
    print("‚ùå –û–®–ò–ë–ö–ê: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    exit()

print("\n" + "=" * 100)
print("–®–ê–ì 1: –ü–ï–†–í–ò–ß–ù–´–ô –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•")
print("=" * 100)

# –ü–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
print("üìã –ü–ï–†–í–´–ï 5 –°–¢–†–û–ö –î–ê–ù–ù–´–•:")
print(df.head())
print("\n" + "-" * 50)

# –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
print("üìä –û–ë–©–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –î–ê–ù–ù–´–•:")
df.info()
print("\n" + "-" * 50)

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∏—Å–ª–æ–≤—ã–º —Å—Ç–æ–ª–±—Ü–∞–º
print("üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ß–ò–°–õ–û–í–´–• –°–¢–û–õ–ë–¶–û–í:")
print(df.describe())
print("\n" + "-" * 50)

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ —Å–æ —Å—Ç–æ–∏–º–æ—Å—Ç—å—é
value_columns = [col for col in df.columns if any(x in col.lower() for x in
                                                  ['value', 'price', 'cost', 'amount', 'fare', 'charge'])]
value_col = value_columns[0] if value_columns else None

if value_col is None:
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 0:
        value_col = numeric_cols[0]
        print(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º —á–∏—Å–ª–æ–≤–æ–π —Å—Ç–æ–ª–±–µ—Ü –∫–∞–∫ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é: '{value_col}'")
    else:
        print("‚ùå –ß–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        exit()

print(f"\nüéØ –¶–ï–õ–ï–í–ê–Ø –ü–ï–†–ï–ú–ï–ù–ù–ê–Ø: '{value_col}'")

# –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
print(f"\nüìä –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó '{value_col}':")
target_stats = {
    '–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ': df[value_col].min(),
    '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ': df[value_col].max(),
    '–°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ': df[value_col].mean(),
    '–ú–µ–¥–∏–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ': df[value_col].median(),
    '–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ': df[value_col].std(),
    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π': (df[value_col] == 0).sum(),
    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π': (df[value_col] < 0).sum(),
    '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π': df[value_col].isnull().sum()
}

for stat, value in target_stats.items():
    print(f"   ‚Ä¢ {stat}: {value:.2f}" if isinstance(value, (int, float)) else f"   ‚Ä¢ {stat}: {value}")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
print("\nüìà –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–Ø –°–¢–û–ò–ú–û–°–¢–ò...")
plt.figure(figsize=(15, 10))

# 1. –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
plt.subplot(2, 3, 1)
plt.hist(df[value_col].dropna(), bins=50, alpha=0.7, color='skyblue', edgecolor='black')
plt.title('–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏', fontsize=12, fontweight='bold')
plt.xlabel('–°—Ç–æ–∏–º–æ—Å—Ç—å –ø–æ–µ–∑–¥–∫–∏')
plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–µ–∑–¥–æ–∫')
plt.grid(True, alpha=0.3)

# 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –±–µ–∑ –∫—Ä–∞–π–Ω–∏—Ö –≤—ã–±—Ä–æ—Å–æ–≤
plt.subplot(2, 3, 2)
upper_99 = df[value_col].quantile(0.99)
filtered_data = df[value_col][df[value_col] <= upper_99]
plt.hist(filtered_data, bins=50, alpha=0.7, color='lightcoral', edgecolor='black')
plt.title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ (–¥–æ 99% –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è: {upper_99:.0f})', fontsize=12, fontweight='bold')
plt.xlabel('–°—Ç–æ–∏–º–æ—Å—Ç—å –ø–æ–µ–∑–¥–∫–∏')
plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–µ–∑–¥–æ–∫')
plt.grid(True, alpha=0.3)

# 3. Boxplot
plt.subplot(2, 3, 3)
plt.boxplot(df[value_col].dropna())
plt.title('Boxplot —Å—Ç–æ–∏–º–æ—Å—Ç–∏', fontsize=12, fontweight='bold')
plt.ylabel('–°—Ç–æ–∏–º–æ—Å—Ç—å')

# 4. –ê–Ω–∞–ª–∏–∑ –≤—ã–±—Ä–æ—Å–æ–≤
plt.subplot(2, 3, 4)
Q1 = df[value_col].quantile(0.25)
Q3 = df[value_col].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

outliers = df[(df[value_col] < lower_bound) | (df[value_col] > upper_bound)]
non_outliers = df[(df[value_col] >= lower_bound) & (df[value_col] <= upper_bound)]

categories = ['–ù–µ –≤—ã–±—Ä–æ—Å—ã', '–í—ã–±—Ä–æ—Å—ã']
counts = [len(non_outliers), len(outliers)]
colors = ['lightblue', 'red']

bars = plt.bar(categories, counts, color=colors, alpha=0.7, edgecolor='black')
plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤', fontsize=12, fontweight='bold')
plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π')

# –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
for bar, count in zip(bars, counts):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + max(counts) * 0.01,
             f'{count}', ha='center', va='bottom', fontweight='bold')

# 5. QQ-plot
plt.subplot(2, 3, 5)
if len(df[value_col].dropna()) > 0:
    stats.probplot(df[value_col].dropna(), dist="norm", plot=plt)
    plt.title('Q-Q plot (–ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏)', fontsize=12, fontweight='bold')

# 6. –ö—É–º—É–ª—è—Ç–∏–≤–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
plt.subplot(2, 3, 6)
sorted_data = np.sort(df[value_col].dropna())
y_vals = np.arange(len(sorted_data)) / float(len(sorted_data))
plt.plot(sorted_data, y_vals, linewidth=2)
plt.title('–ö—É–º—É–ª—è—Ç–∏–≤–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ', fontsize=12, fontweight='bold')
plt.xlabel('–°—Ç–æ–∏–º–æ—Å—Ç—å')
plt.ylabel('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—ã–±—Ä–æ—Å–∞–º
print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –í–´–ë–†–û–°–û–í:")
print(f"   ‚Ä¢ –ù–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ –≤—ã–±—Ä–æ—Å–æ–≤: {lower_bound:.2f}")
print(f"   ‚Ä¢ –í–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ –≤—ã–±—Ä–æ—Å–æ–≤: {upper_bound:.2f}")
print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–±—Ä–æ—Å–æ–≤: {len(outliers)} ({len(outliers) / len(df) * 100:.2f}%)")

if len(outliers) > 0:
    print(f"   ‚Ä¢ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤—ã–±—Ä–æ—Å: {outliers[value_col].min():.2f}")
    print(f"   ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤—ã–±—Ä–æ—Å: {outliers[value_col].max():.2f}")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤
print(f"\nüéØ –û–ë–†–ê–ë–û–¢–ö–ê –í–´–ë–†–û–°–û–í...")
upper_95 = df[value_col].quantile(0.95)
initial_outliers = len(df[df[value_col] > upper_95])
df_processed = df.copy()
df_processed[value_col] = np.where(df_processed[value_col] > upper_95, upper_95, df_processed[value_col])

print(f"   ‚Ä¢ –ü—Ä–∏–º–µ–Ω–µ–Ω–æ Winsorization –Ω–∞ 95% –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª–µ: {upper_95:.2f}")
print(f"   ‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {initial_outliers}")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
print("\nüìà –°–†–ê–í–ù–ï–ù–ò–ï –î–û –ò –ü–û–°–õ–ï –û–ë–†–ê–ë–û–¢–ö–ò...")
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
plt.hist(df_processed[value_col], bins=50, alpha=0.7, color='orange', edgecolor='black')
plt.title('–ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã–±—Ä–æ—Å–æ–≤', fontsize=12, fontweight='bold')
plt.xlabel('–°—Ç–æ–∏–º–æ—Å—Ç—å –ø–æ–µ–∑–¥–∫–∏')
plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–µ–∑–¥–æ–∫')
plt.grid(True, alpha=0.3)

plt.subplot(1, 3, 2)
plt.boxplot(df_processed[value_col].dropna())
plt.title('Boxplot –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏', fontsize=12, fontweight='bold')
plt.ylabel('–°—Ç–æ–∏–º–æ—Å—Ç—å')

plt.subplot(1, 3, 3)
# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–æ –∏ –ø–æ—Å–ª–µ
categories = ['–î–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏', '–ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏']
means = [df[value_col].mean(), df_processed[value_col].mean()]
stds = [df[value_col].std(), df_processed[value_col].std()]

x_pos = np.arange(len(categories))
bars = plt.bar(x_pos, means, yerr=stds, capsize=10, alpha=0.7,
               color=['skyblue', 'lightcoral'], edgecolor='black')
plt.xticks(x_pos, categories)
plt.title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è', fontsize=12, fontweight='bold')
plt.ylabel('–°—Ç–æ–∏–º–æ—Å—Ç—å')

# –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
for i, (mean, std) in enumerate(zip(means, stds)):
    plt.text(i, mean + std + max(means) * 0.05, f'{mean:.1f}¬±{std:.1f}',
             ha='center', va='bottom', fontweight='bold', fontsize=10)

plt.tight_layout()
plt.show()

print(f"\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –î–û –ò –ü–û–°–õ–ï –û–ë–†–ê–ë–û–¢–ö–ò:")
print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {df[value_col].mean():.2f} ‚Üí {df_processed[value_col].mean():.2f}")
print(f"   ‚Ä¢ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {df[value_col].std():.2f} ‚Üí {df_processed[value_col].std():.2f}")
print(f"   ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {df[value_col].max():.2f} ‚Üí {df_processed[value_col].max():.2f}")

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
df = df_processed

print("\n" + "=" * 100)
print("–®–ê–ì 2: –ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´ –î–ê–ù–ù–´–• –ò –°–û–ó–î–ê–ù–ò–ï –ü–†–ò–ó–ù–ê–ö–û–í")
print("=" * 100)

# –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
print("üìã –°–¢–†–£–ö–¢–£–†–ê –î–ê–ù–ù–´–•:")
print(f"   ‚Ä¢ –í—Å–µ–≥–æ —Å—Ç–æ–ª–±—Ü–æ–≤: {len(df.columns)}")
print(f"   ‚Ä¢ –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {len(df)}")

print("\nüìä –¢–ò–ü–´ –î–ê–ù–ù–´–•:")
print(df.dtypes.value_counts())

print("\nüîç –ü–†–û–ü–£–©–ï–ù–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø:")
missing_data = df.isnull().sum()
missing_percent = (df.isnull().sum() / len(df)) * 100
missing_info = pd.DataFrame({
    '–ü—Ä–æ–ø—É—â–µ–Ω–æ': missing_data,
    '–ü—Ä–æ—Ü–µ–Ω—Ç': missing_percent.round(2)
})
missing_info = missing_info[missing_info['–ü—Ä–æ–ø—É—â–µ–Ω–æ'] > 0]
if len(missing_info) > 0:
    print(missing_info)
else:
    print("   ‚Ä¢ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ—Ç")

# –°–ª–æ–≤–∞—Ä—å –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤
column_categories = {
    'vehicle_col': ['vehicle', 'auto', 'car', 'cab'],
    'datetime_col': ['date', 'time', 'datetime', 'timestamp'],
    'payment_col': ['payment', 'method'],
    'distance_col': ['distance', 'km', 'mile', 'length'],
    'duration_col': ['duration', 'time', 'minute', 'hour', 'travel_time'],
    'pickup_col': ['pickup', 'from', 'origin', 'start'],
    'dropoff_col': ['dropoff', 'to', 'destination', 'end'],
    'user_col': ['user', 'customer', 'rider', 'client'],
    'driver_col': ['driver', 'partner']
}

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤
print("\nüéØ –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ï –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –°–¢–û–õ–ë–¶–û–í:")
detected_columns = {}
for category, keywords in column_categories.items():
    for col in df.columns:
        if any(keyword in col.lower() for keyword in keywords):
            detected_columns[category] = col
            print(f"   ‚Ä¢ {category}: '{col}'")
            break

# –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
categorical_features = []
numeric_features = []

for category, col in detected_columns.items():
    if col in df.columns:
        if df[col].dtype == 'object':
            categorical_features.append(col)
        else:
            numeric_features.append(col)

print(f"\nüìã –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –ü–†–ò–ó–ù–ê–ö–û–í:")
print(f"   ‚Ä¢ –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ({len(categorical_features)}): {categorical_features}")
print(f"   ‚Ä¢ –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ({len(numeric_features)}): {numeric_features}")

# –ê–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
if categorical_features:
    print(f"\nüìä –ê–ù–ê–õ–ò–ó –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í:")
    for cat_col in categorical_features:
        unique_count = df[cat_col].nunique()
        print(f"   ‚Ä¢ '{cat_col}': {unique_count} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")

        if unique_count <= 20:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏–π
            value_counts = df[cat_col].value_counts().head(10)
            print(f"     –¢–æ–ø-10 –∑–Ω–∞—á–µ–Ω–∏–π:")
            for value, count in value_counts.items():
                print(f"       - {value}: {count} ({count / len(df) * 100:.1f}%)")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
if categorical_features:
    print("\nüìà –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í...")
    n_cats = min(3, len(categorical_features))
    fig, axes = plt.subplots(1, n_cats, figsize=(15, 5))
    if n_cats == 1:
        axes = [axes]

    for i, cat_col in enumerate(categorical_features[:n_cats]):
        top_categories = df[cat_col].value_counts().head(8)
        axes[i].bar(top_categories.index.astype(str), top_categories.values,
                    color='lightseagreen', alpha=0.7, edgecolor='black')
        axes[i].set_title(f'{cat_col}', fontsize=12, fontweight='bold')
        axes[i].tick_params(axis='x', rotation=45)
        axes[i].grid(True, alpha=0.3)

        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
        for j, value in enumerate(top_categories.values):
            axes[i].text(j, value + max(top_categories.values) * 0.01, f'{value}',
                         ha='center', va='bottom', fontweight='bold')

    plt.tight_layout()
    plt.show()

print("\n" + "=" * 100)
print("–®–ê–ì 3: –°–û–ó–î–ê–ù–ò–ï –†–ê–°–®–ò–†–ï–ù–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í")
print("=" * 100)

all_features = []
time_features = []
statistical_features = []
interaction_features = []
geographic_features = []
behavioral_features = []

print("üîÑ –°–û–ó–î–ê–ù–ò–ï –ü–†–ò–ó–ù–ê–ö–û–í...")

# 1. –í–†–ï–ú–ï–ù–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò
print("\n‚è∞ –í–†–ï–ú–ï–ù–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò:")
datetime_col = detected_columns.get('datetime_col')
if datetime_col and datetime_col in df.columns:
    try:
        df[datetime_col] = pd.to_datetime(df[datetime_col])

        # –ë–∞–∑–æ–≤—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df['hour'] = df[datetime_col].dt.hour
        df['day_of_week'] = df[datetime_col].dt.dayofweek
        df['month'] = df[datetime_col].dt.month
        df['day_of_month'] = df[datetime_col].dt.day
        df['week_of_year'] = df[datetime_col].dt.isocalendar().week
        df['is_weekend'] = (df[datetime_col].dt.dayofweek >= 5).astype(int)

        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df['is_rush_hour'] = (((df['hour'] >= 7) & (df['hour'] <= 10)) |
                              ((df['hour'] >= 16) & (df['hour'] <= 19))).astype(int)
        df['is_night'] = ((df['hour'] >= 23) | (df['hour'] <= 5)).astype(int)

        # –¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
        df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)

        time_features = ['hour', 'day_of_week', 'month', 'day_of_month', 'week_of_year',
                         'is_weekend', 'is_rush_hour', 'is_night',
                         'hour_sin', 'hour_cos', 'day_sin', 'day_cos']

        print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(time_features)} –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
        time_features = []
else:
    print("   ‚ö†Ô∏è –°—Ç–æ–ª–±–µ—Ü –≤—Ä–µ–º–µ–Ω–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")

# 2. –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ï –ü–†–ò–ó–ù–ê–ö–ò
print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ò–ï –ü–†–ò–ó–ù–ê–ö–ò:")

# –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å–ø—Ä–æ—Å–∞
if 'hour' in df.columns:
    df['hourly_demand'] = df.groupby('hour')['hour'].transform('count')
    statistical_features.append('hourly_demand')
    print(f"   ‚Ä¢ hourly_demand - —Å–ø—Ä–æ—Å –ø–æ —á–∞—Å–∞–º")

if 'day_of_week' in df.columns:
    df['daily_demand'] = df.groupby('day_of_week')['day_of_week'].transform('count')
    statistical_features.append('daily_demand')
    print(f"   ‚Ä¢ daily_demand - —Å–ø—Ä–æ—Å –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏")

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —á–∞—Å–∞–º
if 'hour' in df.columns:
    hourly_stats = df.groupby('hour')[value_col].agg(['mean', 'std', 'median']).reset_index()
    hourly_stats.columns = ['hour', 'hourly_mean_price', 'hourly_std_price', 'hourly_median_price']
    df = df.merge(hourly_stats, on='hour', how='left')

    statistical_features.extend(['hourly_mean_price', 'hourly_std_price', 'hourly_median_price'])
    print(f"   ‚Ä¢ hourly_mean_price - —Å—Ä–µ–¥–Ω—è—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–æ —á–∞—Å–∞–º")
    print(f"   ‚Ä¢ hourly_std_price - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –ø–æ —á–∞—Å–∞–º")
    print(f"   ‚Ä¢ hourly_median_price - –º–µ–¥–∏–∞–Ω–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–æ —á–∞—Å–∞–º")

# 3. –ß–ê–°–¢–û–¢–ù–û–ï –ö–û–î–ò–†–û–í–ê–ù–ò–ï –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–• –ü–ï–†–ï–ú–ï–ù–ù–´–•
print("\nüéØ –ß–ê–°–¢–û–¢–ù–û–ï –ö–û–î–ò–†–û–í–ê–ù–ò–ï –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–• –ü–ï–†–ï–ú–ï–ù–ù–´–•:")
for cat_col in categorical_features:
    if cat_col in df.columns:
        freq_encoding = df[cat_col].value_counts().to_dict()
        df[f'{cat_col}_freq'] = df[cat_col].map(freq_encoding)
        statistical_features.append(f'{cat_col}_freq')
        print(f"   ‚Ä¢ {cat_col}_freq - —á–∞—Å—Ç–æ—Ç–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ")

print(f"   ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(categorical_features)} —á–∞—Å—Ç–æ—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

# 4. –ü–†–ò–ó–ù–ê–ö–ò –í–ó–ê–ò–ú–û–î–ï–ô–°–¢–í–ò–Ø
print("\nüîó –ü–†–ò–ó–ù–ê–ö–ò –í–ó–ê–ò–ú–û–î–ï–ô–°–¢–í–ò–Ø:")
if 'hour' in df.columns and 'hourly_demand' in df.columns:
    df['hour_demand_interaction'] = df['hour'] * df['hourly_demand']
    interaction_features.append('hour_demand_interaction')
    print(f"   ‚Ä¢ hour_demand_interaction - –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —á–∞—Å–∞ –∏ —Å–ø—Ä–æ—Å–∞")

if 'is_weekend' in df.columns and 'is_rush_hour' in df.columns:
    df['weekend_rush_interaction'] = df['is_weekend'] * df['is_rush_hour']
    interaction_features.append('weekend_rush_interaction')
    print(f"   ‚Ä¢ weekend_rush_interaction - –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –≤—ã—Ö–æ–¥–Ω—ã—Ö –∏ —á–∞—Å–∞ –ø–∏–∫")

print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(interaction_features)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è")

# 5. –ü–û–í–ï–î–ï–ù–ß–ï–°–ö–ò–ï –ü–†–ò–ó–ù–ê–ö–ò
print("\nüë§ –ü–û–í–ï–î–ï–ù–ß–ï–°–ö–ò–ï –ü–†–ò–ó–ù–ê–ö–ò:")
user_col = detected_columns.get('user_col')
if user_col and user_col in df.columns:
    try:
        user_stats = df.groupby(user_col).agg({
            value_col: ['mean', 'count', 'std']
        }).reset_index()

        user_stats.columns = [user_col, 'user_mean_spend', 'user_ride_count', 'user_std_spend']
        df = df.merge(user_stats, on=user_col, how='left')

        df['user_spend_variability'] = df['user_std_spend'] / (df['user_mean_spend'] + 1e-6)

        behavioral_features = ['user_mean_spend', 'user_ride_count', 'user_std_spend', 'user_spend_variability']
        print(f"   ‚Ä¢ user_mean_spend - —Å—Ä–µ–¥–Ω–∏–µ —Ç—Ä–∞—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
        print(f"   ‚Ä¢ user_ride_count - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–µ–∑–¥–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
        print(f"   ‚Ä¢ user_std_spend - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ —Ç—Ä–∞—Ç")
        print(f"   ‚Ä¢ user_spend_variability - –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç—å —Ç—Ä–∞—Ç")

        print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(behavioral_features)} –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
        behavioral_features = []
else:
    print("   ‚ö†Ô∏è ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ –Ω–∞–π–¥–µ–Ω")

# 6. –ì–ï–û–ì–†–ê–§–ò–ß–ï–°–ö–ò–ï –ü–†–ò–ó–ù–ê–ö–ò
print("\nüìç –ì–ï–û–ì–†–ê–§–ò–ß–ï–°–ö–ò–ï –ü–†–ò–ó–ù–ê–ö–ò:")
coord_cols = [col for col in df.columns if any(x in col.lower() for x in ['lat', 'lon', 'latitude', 'longitude'])]
if len(coord_cols) >= 2:
    lat_col, lon_col = coord_cols[:2]

    valid_coords = df[[lat_col, lon_col]].notna().all(axis=1)
    print(f"   ‚Ä¢ –í–∞–ª–∏–¥–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã: {valid_coords.sum()} –∏–∑ {len(df)}")

    if valid_coords.sum() > 100:
        df['pickup_lat_rounded'] = df[lat_col].round(3)
        df['pickup_lon_rounded'] = df[lon_col].round(3)

        coords = df.loc[valid_coords, [lat_col, lon_col]]
        kmeans = KMeans(n_clusters=min(15, len(coords) // 100), random_state=42)
        df['location_cluster'] = -1
        df.loc[valid_coords, 'location_cluster'] = kmeans.fit_predict(coords)

        geographic_features = ['pickup_lat_rounded', 'pickup_lon_rounded', 'location_cluster']
        print(f"   ‚Ä¢ pickup_lat_rounded - –æ–∫—Ä—É–≥–ª–µ–Ω–Ω–∞—è —à–∏—Ä–æ—Ç–∞")
        print(f"   ‚Ä¢ pickup_lon_rounded - –æ–∫—Ä—É–≥–ª–µ–Ω–Ω–∞—è –¥–æ–ª–≥–æ—Ç–∞")
        print(f"   ‚Ä¢ location_cluster - –∫–ª–∞—Å—Ç–µ—Ä –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—è")

        print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(geographic_features)} –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    else:
        print("   ‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏")
else:
    print("   ‚ö†Ô∏è –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

# –°–ë–û–† –í–°–ï–• –ü–†–ò–ó–ù–ê–ö–û–í
all_features = (numeric_features + time_features + statistical_features +
                interaction_features + geographic_features + behavioral_features)

# –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤ –¥–∞–Ω–Ω—ã—Ö
all_features = list(set([f for f in all_features if f in df.columns]))

print(f"\nüìã –ò–¢–û–ì–û –°–û–ó–î–ê–ù–û –ü–†–ò–ó–ù–ê–ö–û–í: {len(all_features)}")
print(f"   ‚Ä¢ –ß–∏—Å–ª–æ–≤—ã–µ: {len(numeric_features)}")
print(f"   ‚Ä¢ –í—Ä–µ–º–µ–Ω–Ω—ã–µ: {len(time_features)}")
print(f"   ‚Ä¢ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ: {len([f for f in statistical_features if f in df.columns])}")
print(f"   ‚Ä¢ –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è: {len(interaction_features)}")
print(f"   ‚Ä¢ –ì–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ: {len(geographic_features)}")
print(f"   ‚Ä¢ –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ: {len(behavioral_features)}")

print("\n" + "=" * 100)
print("–®–ê–ì 4: –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –ú–û–î–ï–õ–ò")
print("=" * 100)

print("üßπ –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•...")

# –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º
final_data = df[all_features + [value_col]].copy()
print(f"   ‚Ä¢ –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {final_data.shape}")

# –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤
print("\nüîß –ó–ê–ü–û–õ–ù–ï–ù–ò–ï –ü–†–û–ü–£–©–ï–ù–ù–´–• –ó–ù–ê–ß–ï–ù–ò–ô...")
for col in final_data.columns:
    if final_data[col].isnull().sum() > 0:
        if final_data[col].dtype in ['float64', 'int64']:
            fill_value = final_data[col].median() if final_data[col].notna().sum() > 0 else 0
            final_data[col] = final_data[col].fillna(fill_value)
            print(f"   ‚Ä¢ {col}: –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –º–µ–¥–∏–∞–Ω–æ–π ({fill_value:.2f})")
        else:
            fill_value = final_data[col].mode()[0] if not final_data[col].mode().empty else 'Unknown'
            final_data[col] = final_data[col].fillna(fill_value)
            print(f"   ‚Ä¢ {col}: –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –º–æ–¥–æ–π ('{fill_value}')")

# –ö–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
print("\nüî§ –ö–û–î–ò–†–û–í–ê–ù–ò–ï –ö–ê–¢–ï–ì–û–†–ò–ê–õ–¨–ù–´–• –ü–ï–†–ï–ú–ï–ù–ù–´–•...")
label_encoders = {}
for col in categorical_features:
    if col in final_data.columns:
        try:
            le = LabelEncoder()
            final_data[col] = le.fit_transform(final_data[col].astype(str))
            label_encoders[col] = le
            print(f"   ‚Ä¢ {col}: —É—Å–ø–µ—à–Ω–æ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω ({len(le.classes_)} –∫–ª–∞—Å—Å–æ–≤)")
        except Exception as e:
            print(f"   ‚Ä¢ {col}: –æ—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è - {e}")

print(f"\n‚úÖ –î–ê–ù–ù–´–ï –ü–û–î–ì–û–¢–û–í–õ–ï–ù–´")
print(f"   ‚Ä¢ –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {final_data.shape}")
print(f"   ‚Ä¢ –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: '{value_col}'")
print(f"   ‚Ä¢ –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(all_features)}")

print("\n" + "=" * 100)
print("–®–ê–ì 5: –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –ú–ê–®–ò–ù–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø")
print("=" * 100)

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
X = final_data.drop(columns=[value_col])
y = final_data[value_col]

# –£–¥–∞–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ NaN –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π
mask = ~(X.isnull().any(axis=1) | y.isnull())
X = X[mask]
y = y[mask]

print(f"üéØ –†–ê–ó–ú–ï–†–ù–û–°–¢–¨ –î–õ–Ø –û–ë–£–ß–ï–ù–ò–Ø:")
print(f"   ‚Ä¢ –ü—Ä–∏–∑–Ω–∞–∫–∏ (X): {X.shape}")
print(f"   ‚Ä¢ –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (y): {y.shape}")

# –°—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –∫–≤–∞–Ω—Ç–∏–ª—è–º —Å—Ç–æ–∏–º–æ—Å—Ç–∏
try:
    y_bins = pd.qcut(y, q=5, duplicates='drop')
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y_bins
    )
    print("‚úÖ –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ")
except Exception as e:
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    print("‚ö†Ô∏è –û–±—ã—á–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ (—Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å)")

print(f"\nüìö –†–ê–ó–ú–ï–†–´ –í–´–ë–û–†–û–ö:")
print(f"   ‚Ä¢ –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_train.shape[0]} –∑–∞–ø–∏—Å–µ–π")
print(f"   ‚Ä¢ –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {X_test.shape[0]} –∑–∞–ø–∏—Å–µ–π")
print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X_train.shape[1]}")

# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
print("\n‚öñÔ∏è –ú–ê–°–®–¢–ê–ë–ò–†–û–í–ê–ù–ò–ï –ü–†–ò–ó–ù–ê–ö–û–í...")
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
print("‚úÖ –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

# –û–±—É—á–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π
print("\nü§ñ –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô...")

models = {
    'Random Forest': RandomForestRegressor(
        n_estimators=100,
        max_depth=20,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42,
        n_jobs=-1
    ),
    'Gradient Boosting': GradientBoostingRegressor(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        random_state=42
    )
}

results = {}

for name, model in models.items():
    print(f"   üöÄ –û–±—É—á–µ–Ω–∏–µ {name}...")
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)

    # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)
    mape = np.mean(np.abs((y_test - y_pred) / np.where(y_test == 0, 1, y_test))) * 100

    results[name] = {
        'model': model,
        'mae': mae,
        'rmse': rmse,
        'r2': r2,
        'mape': mape,
        'predictions': y_pred
    }

    print(f"   ‚úÖ {name}:")
    print(f"      R¬≤ = {r2:.4f}")
    print(f"      MAE = {mae:.2f}")
    print(f"      RMSE = {rmse:.2f}")
    print(f"      MAPE = {mape:.2f}%")

# –í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
best_model_name = max(results.keys(), key=lambda x: results[x]['r2'])
best_model = results[best_model_name]
print(f"\nüèÜ –õ–£–ß–®–ê–Ø –ú–û–î–ï–õ–¨: {best_model_name}")

print("\n" + "=" * 100)
print("–®–ê–ì 6: –û–¶–ï–ù–ö–ê –ö–ê–ß–ï–°–¢–í–ê –ú–û–î–ï–õ–ò")
print("=" * 100)

y_pred = best_model['predictions']

print("üìä –ú–ï–¢–†–ò–ö–ò –ö–ê–ß–ï–°–¢–í–ê –õ–£–ß–®–ï–ô –ú–û–î–ï–õ–ò:")
print(f"‚Ä¢ MAE (–°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞): {best_model['mae']:.2f}")
print(f"‚Ä¢ RMSE (–°—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞): {best_model['rmse']:.2f}")
print(f"‚Ä¢ R¬≤ (–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏): {best_model['r2']:.4f}")
print(f"‚Ä¢ MAPE (–°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–∞—è –æ—à–∏–±–∫–∞): {best_model['mape']:.2f}%")

# –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫
print(f"\nüìà –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –û–®–ò–ë–û–ö:")
error_stats = pd.DataFrame({
    '–§–∞–∫—Ç': y_test,
    '–ü—Ä–æ–≥–Ω–æ–∑': y_pred,
    '–û—à–∏–±–∫–∞': y_test - y_pred,
    '–ê–±—Å–æ–ª—é—Ç–Ω–∞—è_–æ—à–∏–±–∫–∞': np.abs(y_test - y_pred),
    '–ü—Ä–æ—Ü–µ–Ω—Ç–Ω–∞—è_–æ—à–∏–±–∫–∞': np.abs(y_test - y_pred) / np.where(y_test == 0, 1, y_test) * 100
})

print("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—à–∏–±–æ–∫:")
print(f"‚Ä¢ –ú–µ–¥–∏–∞–Ω–Ω–∞—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {error_stats['–ê–±—Å–æ–ª—é—Ç–Ω–∞—è_–æ—à–∏–±–∫–∞'].median():.2f}")
print(f"‚Ä¢ 75-–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å –æ—à–∏–±–∫–∏: {error_stats['–ê–±—Å–æ–ª—é—Ç–Ω–∞—è_–æ—à–∏–±–∫–∞'].quantile(0.75):.2f}")
print(f"‚Ä¢ 90-–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å –æ—à–∏–±–∫–∏: {error_stats['–ê–±—Å–æ–ª—é—Ç–Ω–∞—è_–æ—à–∏–±–∫–∞'].quantile(0.9):.2f}")
print(f"‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞: {error_stats['–ê–±—Å–æ–ª—é—Ç–Ω–∞—è_–æ—à–∏–±–∫–∞'].max():.2f}")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
print("\nüìà –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–û–í...")
plt.figure(figsize=(18, 6))

# 1. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è vs –§–∞–∫—Ç
plt.subplot(1, 3, 1)
plt.scatter(y_test, y_pred, alpha=0.6, s=20, color='blue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='–ò–¥–µ–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è')
plt.xlabel('–§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å')
plt.ylabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å')
plt.title('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è vs –§–∞–∫—Ç', fontsize=12, fontweight='bold')
plt.grid(True, alpha=0.3)
plt.legend()

# –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–Ω–∏—é —Ç—Ä–µ–Ω–¥–∞
z = np.polyfit(y_test, y_pred, 1)
p = np.poly1d(z)
plt.plot(y_test, p(y_test), "g--", alpha=0.8, label=f'–¢—Ä–µ–Ω–¥: y={z[0]:.2f}x+{z[1]:.2f}')
plt.legend()

# 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫
plt.subplot(1, 3, 2)
errors = y_test - y_pred
plt.hist(errors, bins=50, alpha=0.7, color='orange', edgecolor='black')
plt.axvline(x=0, color='red', linestyle='--', linewidth=2, label='–ù—É–ª–µ–≤–∞—è –æ—à–∏–±–∫–∞')
plt.xlabel('–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è')
plt.ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫', fontsize=12, fontweight='bold')
plt.grid(True, alpha=0.3)
plt.legend()

# 3. –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
plt.subplot(1, 3, 3)
model_for_importance = best_model['model']
if hasattr(model_for_importance, 'feature_importances_'):
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': model_for_importance.feature_importances_
    }).sort_values('importance', ascending=False).head(15)

    bars = plt.barh(feature_importance['feature'], feature_importance['importance'],
                    color='green', alpha=0.7, edgecolor='black')
    plt.xlabel('–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∞')
    plt.title('–¢–æ–ø-15 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontsize=12, fontweight='bold')
    plt.gca().invert_yaxis()

    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
    for bar in bars:
        width = bar.get_width()
        plt.text(width + max(feature_importance['importance']) * 0.01, bar.get_y() + bar.get_height() / 2,
                 f'{width:.3f}', ha='left', va='center', fontweight='bold')
else:
    plt.text(0.5, 0.5, '–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n–Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞',
             ha='center', va='center', transform=plt.gca().transAxes, fontsize=12)

plt.tight_layout()
plt.show()

print("\n" + "=" * 100)
print("–®–ê–ì 7: –ë–ò–ó–ù–ï–°-–ê–ù–ê–õ–ò–ó –ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò")
print("=" * 100)

print("üí∞ –ö–õ–Æ–ß–ï–í–´–ï –ò–ù–°–ê–ô–¢–´:")

# –ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —Å—Ç–æ–∏–º–æ—Å—Ç—å
if 'hour' in df.columns:
    hourly_analysis = df.groupby('hour').agg({
        value_col: ['mean', 'count']
    }).round(2)
    hourly_analysis.columns = ['avg_price', 'ride_count']
    hourly_analysis = hourly_analysis.sort_values('avg_price', ascending=False)

    print(f"\n‚è∞ –¢–û–ü-5 –°–ê–ú–´–• –î–û–†–û–ì–ò–• –ß–ê–°–û–í:")
    for hour, row in hourly_analysis.head().iterrows():
        print(f"   ‚Ä¢ {hour:02d}:00 - {row['avg_price']:.2f} (–ø–æ–µ–∑–¥–æ–∫: {row['ride_count']})")

# –ê–Ω–∞–ª–∏–∑ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏
if 'day_of_week' in df.columns:
    weekday_analysis = df.groupby('day_of_week').agg({
        value_col: ['mean', 'count']
    }).round(2)
    weekday_analysis.columns = ['avg_price', 'ride_count']
    days = ['–ü–Ω', '–í—Ç', '–°—Ä', '–ß—Ç', '–ü—Ç', '–°–±', '–í—Å']
    weekday_analysis.index = [days[i] for i in weekday_analysis.index]

    print(f"\nüìÖ –°–¢–û–ò–ú–û–°–¢–¨ –ü–û –î–ù–Ø–ú –ù–ï–î–ï–õ–ò:")
    for day, row in weekday_analysis.iterrows():
        print(f"   ‚Ä¢ {day} - {row['avg_price']:.2f} (–ø–æ–µ–∑–¥–æ–∫: {row['ride_count']})")

# –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø—É —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞
vehicle_col = detected_columns.get('vehicle_col')
if vehicle_col and vehicle_col in df.columns:
    vehicle_analysis = df.groupby(vehicle_col).agg({
        value_col: ['mean', 'count']
    }).round(2)
    vehicle_analysis.columns = ['avg_price', 'ride_count']
    vehicle_analysis = vehicle_analysis.sort_values('avg_price', ascending=False)

    print(f"\nüöó –°–¢–û–ò–ú–û–°–¢–¨ –ü–û –¢–ò–ü–ê–ú –¢–†–ê–ù–°–ü–û–†–¢–ê:")
    for vehicle, row in vehicle_analysis.iterrows():
        print(f"   ‚Ä¢ {vehicle} - {row['avg_price']:.2f} (–ø–æ–µ–∑–¥–æ–∫: {row['ride_count']})")

print("\nüéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –ë–ò–ó–ù–ï–°–ê:")

print("\n1. üöÄ –û–ü–ï–†–ê–¶–ò–û–ù–ù–´–ï –£–õ–£–ß–®–ï–ù–ò–Ø:")
print("   ‚Ä¢ –í–Ω–µ–¥—Ä–∏—Ç–µ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ —Ü–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
print("   ‚Ä¢ –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞ –≤ —á–∞—Å—ã –ø–∏–∫")
print("   ‚Ä¢ –†–∞–∑—Ä–∞–±–æ—Ç–∞–π—Ç–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–∞—Ä–∏—Ñ—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω")

print("\n2. üìà –£–ü–†–ê–í–õ–ï–ù–ò–ï –î–û–•–û–î–ê–ú–ò:")
print("   ‚Ä¢ –°—Ñ–æ–∫—É—Å–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏–∏ –ø—Ä–µ–º–∏–∞–ª—å–Ω—ã—Ö —É—Å–ª—É–≥ –≤ –¥–æ—Ä–æ–≥–∏–µ —á–∞—Å—ã")
print("   ‚Ä¢ –†–∞–∑—Ä–∞–±–æ—Ç–∞–π—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤")
print("   ‚Ä¢ –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ —Ü–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ø—Ä–æ—Å–∞")

print("\n3. üîß –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –£–õ–£–ß–®–ï–ù–ò–Ø:")
print("   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ø—Ä–æ—Å–∞")
print("   ‚Ä¢ –í–Ω–µ–¥—Ä–∏—Ç–µ —Å–∏—Å—Ç–µ–º—É —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
print("   ‚Ä¢ –°–æ–∑–¥–∞–π—Ç–µ –¥–∞—à–±–æ—Ä–¥—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫")

print("\n" + "=" * 100)
print("–ò–¢–û–ì–ò –ú–û–î–ï–õ–ò–†–û–í–ê–ù–ò–Ø")
print("=" * 100)

print("‚úÖ –û–°–ù–û–í–ù–´–ï –î–û–°–¢–ò–ñ–ï–ù–ò–Ø:")
print(f"‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")
print(f"‚Ä¢ –°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(all_features)}")
print(f"‚Ä¢ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name}")
print(f"‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ (R¬≤): {best_model['r2']:.4f}")
print(f"‚Ä¢ –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞: {best_model['mape']:.2f}%")
print(f"‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∞: {100 - best_model['mape']:.1f}%")

# –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
if hasattr(model_for_importance, 'feature_importances_'):
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': model_for_importance.feature_importances_
    }).sort_values('importance', ascending=False)

    print(f"\nüéØ –¢–û–ü-10 –í–ê–ñ–ù–ï–ô–®–ò–• –§–ê–ö–¢–û–†–û–í –°–¢–û–ò–ú–û–°–¢–ò:")
    top_factors = feature_importance.head(10)
    for i, (_, row) in enumerate(top_factors.iterrows(), 1):
        print(f"{i:2d}. {row['feature']}: {row['importance']:.4f}")

print("\nüöÄ –î–ê–õ–¨–ù–ï–ô–®–ò–ï –®–ê–ì–ò:")
print("1. –í–Ω–µ–¥—Ä–∏—Ç—å –º–æ–¥–µ–ª—å –≤ production-—Å–∏—Å—Ç–µ–º—É")
print("2. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
print("3. –†–µ–≥—É–ª—è—Ä–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
print("4. –î–æ–±–∞–≤–∏—Ç—å –≤–Ω–µ—à–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ (–ø–æ–≥–æ–¥–∞, –ø—Ä–æ–±–∫–∏, —Å–æ–±—ã—Ç–∏—è)")
print("5. –†–∞—Å—à–∏—Ä–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏")

print("\n" + "=" * 100)
print("–ú–û–î–ï–õ–¨ –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø –°–¢–û–ò–ú–û–°–¢–ò –£–°–ü–ï–®–ù–û –°–û–ó–î–ê–ù–ê –ò –ü–†–û–¢–ï–°–¢–ò–†–û–í–ê–ù–ê!")
print("=" * 100)

# –ü—Ä–∏–º–µ—Ä –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
print(f"\nüîÆ –ü–†–ò–ú–ï–† –ü–†–û–ì–ù–û–ó–ê –î–õ–Ø –ù–û–í–´–• –î–ê–ù–ù–´–•:")
sample_indices = X_test.sample(min(3, len(X_test)), random_state=42).index
print("\n–ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–≥–Ω–æ–∑–æ–≤:")
print("-" * 80)
print(f"{'‚Ññ':<3} {'–§–∞–∫—Ç':<10} {'–ü—Ä–æ–≥–Ω–æ–∑':<10} {'–û—à–∏–±–∫–∞':<10} {'–¢–æ—á–Ω–æ—Å—Ç—å':<10}")
print("-" * 80)

for i, idx in enumerate(sample_indices, 1):
    actual = y_test.loc[idx]
    predicted = y_pred[X_test.index.get_loc(idx)]
    error = abs(actual - predicted)
    accuracy = (1 - error / actual) * 100 if actual != 0 else 100

    print(f"{i:<3} {actual:<10.2f} {predicted:<10.2f} {error:<10.2f} {accuracy:<10.1f}%")

print("-" * 80)

